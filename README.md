# LangChain Local LLM with Ollama

## Description

This project demonstrates how to integrate and run a local LLaMA 3 language model using the langchain_ollama Python package within a Docker container environment and uv. It showcases a simple use case where the model acts as a helpful assistant that translates English sentences into Spanish.

Article: [LangChain with Ollama and Docker]()

## Requirements

- Docker with support to GPU.

## Run project

```Bash
sh ./run.sh
```

## References

- [ChatOllama](https://python.langchain.com/docs/integrations/chat/ollama/)
- [Ollama is now available as an official Docker image](https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image)
