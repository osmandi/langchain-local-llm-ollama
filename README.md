# LangChain Local LLM with Ollama

## Description

This project demonstrates how to integrate and run a local LLaMA 3 language model using the langchain_ollama Python package within a Docker container environment and uv. It showcases a simple use case where the model acts as a helpful assistant that translates English sentences into Spanish.

## Requirements

- Docker with support to GPU.

## Run project

```Bash
sh ./run.sh
```
